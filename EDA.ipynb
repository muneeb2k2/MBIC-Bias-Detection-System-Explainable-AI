{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-1M7VEPjtaZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "COMPLETE NOTEBOOK 2: MULTI-STRATEGY MODEL TRAINING\n",
        "================================================================================\n",
        "This notebook trains THREE different approaches:\n",
        "1. Traditional GridSearchCV with regularization\n",
        "2. Confidence-based classification\n",
        "3. Disagreement-based ensemble\n",
        "\n",
        "Then compares all approaches and selects the best.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "TA57VPZbkpjX",
        "outputId": "772ab49f-5ec2-4237-c541-64e8c6342350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n================================================================================\\nCOMPLETE NOTEBOOK 2: MULTI-STRATEGY MODEL TRAINING\\n================================================================================\\nThis notebook trains THREE different approaches:\\n1. Traditional GridSearchCV with regularization\\n2. Confidence-based classification\\n3. Disagreement-based ensemble\\n\\nThen compares all approaches and selects the best.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SETUP\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import time\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "-we9MBOZkxRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    f1_score\n",
        ")\n",
        "from scipy.stats import entropy\n",
        "\n",
        "# Imbalance handling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "# Optional: XGBoost\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except ImportError:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "    print(\"âš  XGBoost not available\")\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"MBIC BIAS DETECTION - COMPLETE PIPELINE\")\n",
        "print(\"Notebook 2: Multi-Strategy Model Training\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjjtxAJ5k0Zu",
        "outputId": "76be85a1-3fb4-4b9d-e0c7-bbec4c8c9575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "MBIC BIAS DETECTION - COMPLETE PIPELINE\n",
            "Notebook 2: Multi-Strategy Model Training\n",
            "================================================================================\n",
            "Started at: 2025-12-11 15:34:57\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ADD THIS TO MOUNT DRIVE ---\n",
        "from google.colab import drive\n",
        "\n",
        "# Define the exact same persistent path used for saving in Notebook 1\n",
        "DRIVE_PATH = '/content/drive/MyDrive/MBIC_Artifacts/'\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "print(f\"\\nâœ“ Google Drive mounted. Artifacts will be loaded from: {DRIVE_PATH}\")\n",
        "# -------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiPAQ6dmEiut",
        "outputId": "5a776323-86cf-470e-eedb-757483f9aea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "âœ“ Google Drive mounted. Artifacts will be loaded from: /content/drive/MyDrive/MBIC_Artifacts/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 1: LOAD FEATURES AND LABELS (MODIFIED)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STEP 1: LOADING DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load hybrid features\n",
        "X = np.load(DRIVE_PATH + 'hybrid_features.npy')\n",
        "y = np.load(DRIVE_PATH + 'labels_encoded.npy')\n",
        "label_encoder = joblib.load(DRIVE_PATH + 'label_encoder.pkl')\n",
        "\n",
        "print(f\"âœ“ Features loaded: {X.shape}\")\n",
        "print(f\"âœ“ Labels loaded: {y.shape}\")\n",
        "\n",
        "# Get string labels\n",
        "y_labels = label_encoder.inverse_transform(y)\n",
        "\n",
        "print(\"\\nClass distribution:\")\n",
        "for label in label_encoder.classes_:\n",
        "    count = (y_labels == label).sum()\n",
        "    print(f\" Â {label:15s}: {count:4d} ({count/len(y)*100:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gLnIhtek8SA",
        "outputId": "a4bbf966-e56d-4625-9c59-d151a102e726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 1: LOADING DATA\n",
            "================================================================================\n",
            "âœ“ Features loaded: (1700, 1170)\n",
            "âœ“ Labels loaded: (1700,)\n",
            "\n",
            "Class distribution:\n",
            " Â Biased         : 1018 (59.9%)\n",
            " Â No agreement   :  149 (8.8%)\n",
            " Â Non-biased     :  533 (31.4%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 2: SPLIT DATA\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STEP 2: SPLITTING DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Split: 60% train, 20% val, 20% test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.4,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.5,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "# Also get string labels for splits\n",
        "y_train_labels = label_encoder.inverse_transform(y_train)\n",
        "y_val_labels = label_encoder.inverse_transform(y_val)\n",
        "y_test_labels = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "print(f\"\\nData split:\")\n",
        "print(f\"  Train: {len(X_train):4d} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"  Val:   {len(X_val):4d} samples ({len(X_val)/len(X)*100:.1f}%)\")\n",
        "print(f\"  Test:  {len(X_test):4d} samples ({len(X_test)/len(X)*100:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzmCf9Z_k_FV",
        "outputId": "6bbec1b2-8873-49e1-8ec6-83c661265cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 2: SPLITTING DATA\n",
            "================================================================================\n",
            "\n",
            "Data split:\n",
            "  Train: 1020 samples (60.0%)\n",
            "  Val:    340 samples (20.0%)\n",
            "  Test:   340 samples (20.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 3: DATA BALANCING (CONSERVATIVE SMOTE + TOMEK LINKS)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STEP 3: BALANCING TRAINING DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nOriginal training distribution:\")\n",
        "for idx, label in enumerate(label_encoder.classes_):\n",
        "    count = (y_train == idx).sum()\n",
        "    print(f\"  {label:15s}: {count:4d}\")\n",
        "\n",
        "# Apply Tomek Links (remove noisy samples)\n",
        "print(\"\\nApplying Tomek Links to clean boundaries...\")\n",
        "tomek = TomekLinks(sampling_strategy='auto')\n",
        "X_train_clean, y_train_clean = tomek.fit_resample(X_train, y_train)\n",
        "\n",
        "removed = len(X_train) - len(X_train_clean)\n",
        "print(f\"âœ“ Removed {removed} noisy samples\")\n",
        "\n",
        "# Conservative SMOTE - only upsample minority class to moderate level\n",
        "print(\"\\nApplying Conservative SMOTE...\")\n",
        "unique, counts = np.unique(y_train_clean, return_counts=True)\n",
        "max_count = counts.max()\n",
        "\n",
        "# Upsample minority to 40% of majority (conservative)\n",
        "target_count = int(max_count * 0.4)\n",
        "sampling_strategy = {\n",
        "    cls: max(count, target_count)\n",
        "    for cls, count in zip(unique, counts)\n",
        "}\n",
        "\n",
        "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=RANDOM_STATE, k_neighbors=3)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_clean, y_train_clean)\n",
        "\n",
        "print(f\"\\nBalanced training distribution:\")\n",
        "for idx, label in enumerate(label_encoder.classes_):\n",
        "    count = (y_train_balanced == idx).sum()\n",
        "    original = (y_train == idx).sum()\n",
        "    change = count - original\n",
        "    print(f\"  {label:15s}: {count:4d} (original: {original}, +{change})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsmOpzpmlDFt",
        "outputId": "61086a2f-3fcd-4f71-999a-fea3aa602ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STEP 3: BALANCING TRAINING DATA\n",
            "================================================================================\n",
            "\n",
            "Original training distribution:\n",
            "  Biased         :  611\n",
            "  No agreement   :   89\n",
            "  Non-biased     :  320\n",
            "\n",
            "Applying Tomek Links to clean boundaries...\n",
            "âœ“ Removed 182 noisy samples\n",
            "\n",
            "Applying Conservative SMOTE...\n",
            "\n",
            "Balanced training distribution:\n",
            "  Biased         :  511 (original: 611, +-100)\n",
            "  No agreement   :  204 (original: 89, +115)\n",
            "  Non-biased     :  238 (original: 320, +-82)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STRATEGY 1: TRADITIONAL GRIDSEARCHCV WITH STRONG REGULARIZATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STRATEGY 1: TRADITIONAL GRIDSEARCHCV\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "models_strategy1 = {\n",
        "    'Logistic Regression': {\n",
        "        'model': LogisticRegression(\n",
        "            random_state=RANDOM_STATE,\n",
        "            max_iter=1000,\n",
        "            class_weight='balanced'\n",
        "        ),\n",
        "        'params': {\n",
        "            'C': [0.01, 0.1, 0.5, 1.0],  # Stronger L2 regularization (C=0.01)\n",
        "            'penalty': ['l2'],\n",
        "            'solver': ['lbfgs']\n",
        "        }\n",
        "    },\n",
        "    'SVM': {\n",
        "        'model': SVC(\n",
        "            random_state=RANDOM_STATE,\n",
        "            class_weight='balanced',\n",
        "            probability=True\n",
        "        ),\n",
        "        'params': {\n",
        "            'C': [0.1, 0.5, 1.0], # Reduced C range to test more regularization\n",
        "            'kernel': ['rbf'],\n",
        "            'gamma': ['scale']\n",
        "        }\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'model': RandomForestClassifier(\n",
        "            random_state=RANDOM_STATE,\n",
        "            class_weight='balanced',\n",
        "            n_jobs=-1\n",
        "        ),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],\n",
        "            'max_depth': [10, 15, 20], # Testing a slightly lower max_depth (10)\n",
        "            'min_samples_split': [10, 20],\n",
        "            'min_samples_leaf': [5, 10]\n",
        "        }\n",
        "    },\n",
        "    'MLP': {\n",
        "        'model': MLPClassifier(\n",
        "            random_state=RANDOM_STATE,\n",
        "            early_stopping=True,\n",
        "            validation_fraction=0.1,\n",
        "            n_iter_no_change=10\n",
        "        ),\n",
        "        'params': {\n",
        "            'hidden_layer_sizes': [(128, 64), (256, 128)],\n",
        "            'alpha': [0.01, 0.001, 0.0001],  # Expanded L2 regularization range\n",
        "            'learning_rate_init': [0.001]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "if XGBOOST_AVAILABLE:\n",
        "    models_strategy1['XGBoost'] = {\n",
        "        'model': XGBClassifier(\n",
        "            random_state=RANDOM_STATE,\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='mlogloss',\n",
        "            n_jobs=-1,\n",
        "            # Aggressive early stopping to reduce time\n",
        "            early_stopping_rounds=20\n",
        "        ),\n",
        "        'params': {\n",
        "            'n_estimators': [100, 200],\n",
        "            'max_depth': [3, 5],\n",
        "            'learning_rate': [0.01, 0.05], # Slower learning rates\n",
        "            'subsample': [0.8],\n",
        "            'reg_alpha': [0.1, 1.0, 5.0],  # Increased L1 regularization\n",
        "            'reg_lambda': [1.0, 10.0]      # Increased L2 regularization\n",
        "        }\n",
        "    }\n",
        "\n",
        "results_strategy1 = {}\n",
        "\n",
        "for model_name, config in models_strategy1.items():\n",
        "    print(f\"\\n{'-'*80}\")\n",
        "    print(f\"Training: {model_name}\")\n",
        "    print(f\"{'-'*80}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=config['model'],\n",
        "        param_grid=config['params'],\n",
        "        cv=cv,\n",
        "        scoring='f1_macro',\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # NOTE: Using X_train_balanced and y_train_balanced suggests you are\n",
        "    # already using some form of oversampling/undersampling.\n",
        "    grid_search.fit(X_train_balanced, y_train_balanced)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    y_val_pred = grid_search.predict(X_val)\n",
        "    val_f1_macro = f1_score(y_val, y_val_pred, average='macro')\n",
        "    val_f1_weighted = f1_score(y_val, y_val_pred, average='weighted')\n",
        "\n",
        "    # Store results\n",
        "    results_strategy1[model_name] = {\n",
        "        'estimator': grid_search.best_estimator_,\n",
        "        'best_params': grid_search.best_params_,\n",
        "        'cv_f1_macro': grid_search.best_score_,\n",
        "        'val_f1_macro': val_f1_macro,\n",
        "        'val_f1_weighted': val_f1_weighted,\n",
        "        'training_time': training_time\n",
        "    }\n",
        "\n",
        "    print(f\"\\nâœ“ Completed in {training_time:.2f}s\")\n",
        "    print(f\" Â Best CV F1 Macro: {grid_search.best_score_:.4f}\")\n",
        "    print(f\" Â Val F1 Macro: {val_f1_macro:.4f}\")\n",
        "    print(f\" Â Best params: {grid_search.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KqV3Vh4GlPt8",
        "outputId": "e21edad4-8f8f-4b0e-ba3c-20087204ef1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STRATEGY 1: TRADITIONAL GRIDSEARCHCV\n",
            "================================================================================\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Training: Logistic Regression\n",
            "--------------------------------------------------------------------------------\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "\n",
            "âœ“ Completed in 8.47s\n",
            " Â Best CV F1 Macro: 0.6771\n",
            " Â Val F1 Macro: 0.4816\n",
            " Â Best params: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Training: SVM\n",
            "--------------------------------------------------------------------------------\n",
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "\n",
            "âœ“ Completed in 33.79s\n",
            " Â Best CV F1 Macro: 0.6085\n",
            " Â Val F1 Macro: 0.4160\n",
            " Â Best params: {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Training: Random Forest\n",
            "--------------------------------------------------------------------------------\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "\n",
            "âœ“ Completed in 306.61s\n",
            " Â Best CV F1 Macro: 0.7119\n",
            " Â Val F1 Macro: 0.4379\n",
            " Â Best params: {'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Training: MLP\n",
            "--------------------------------------------------------------------------------\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "\n",
            "âœ“ Completed in 43.47s\n",
            " Â Best CV F1 Macro: 0.6864\n",
            " Â Val F1 Macro: 0.4388\n",
            " Â Best params: {'alpha': 0.0001, 'hidden_layer_sizes': (256, 128), 'learning_rate_init': 0.001}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Training: XGBoost\n",
            "--------------------------------------------------------------------------------\n",
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/core.py\", line 774, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/sklearn.py\", line 1806, in fit\n    self._Booster = train(\n                    ^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/core.py\", line 774, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/training.py\", line 200, in train\n    if cb_container.after_iteration(bst, i, dtrain, evals):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/callback.py\", line 269, in after_iteration\n    ret = any(c.after_iteration(model, epoch, self.history) for c in self.callbacks)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/callback.py\", line 269, in <genexpr>\n    ret = any(c.after_iteration(model, epoch, self.history) for c in self.callbacks)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/callback.py\", line 461, in after_iteration\n    raise ValueError(msg)\nValueError: Must have at least 1 validation dataset for early stopping.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1033289110.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# NOTE: Using X_train_balanced and y_train_balanced suggests you are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# already using some form of oversampling/undersampling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_balanced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_balanced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mtraining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    999\u001b[0m                     )\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             )\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n240 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/core.py\", line 774, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/sklearn.py\", line 1806, in fit\n    self._Booster = train(\n                    ^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/core.py\", line 774, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/training.py\", line 200, in train\n    if cb_container.after_iteration(bst, i, dtrain, evals):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/callback.py\", line 269, in after_iteration\n    ret = any(c.after_iteration(model, epoch, self.history) for c in self.callbacks)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/callback.py\", line 269, in <genexpr>\n    ret = any(c.after_iteration(model, epoch, self.history) for c in self.callbacks)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/xgboost/callback.py\", line 461, in after_iteration\n    raise ValueError(msg)\nValueError: Must have at least 1 validation dataset for early stopping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STRATEGY 2: CONFIDENCE-BASED CLASSIFICATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STRATEGY 2: CONFIDENCE-BASED CLASSIFICATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "class ConfidenceBasedClassifier:\n",
        "    def __init__(self, confidence_threshold=0.6):\n",
        "        self.threshold = confidence_threshold\n",
        "        self.binary_classifier = LogisticRegression(\n",
        "            random_state=RANDOM_STATE,\n",
        "            max_iter=1000,\n",
        "            class_weight='balanced',\n",
        "            C=1.0\n",
        "        )\n",
        "        self.calibrated_classifier = None\n",
        "\n",
        "    def fit(self, X, y, y_labels):\n",
        "        # Train on binary problem (exclude \"No agreement\")\n",
        "        biased_mask = (y_labels == 'Biased')\n",
        "        non_biased_mask = (y_labels == 'Non-biased')\n",
        "        binary_mask = biased_mask | non_biased_mask\n",
        "\n",
        "        X_binary = X[binary_mask]\n",
        "        y_binary = biased_mask[binary_mask].astype(int)\n",
        "\n",
        "        self.binary_classifier.fit(X_binary, y_binary)\n",
        "\n",
        "        # Calibrate\n",
        "        self.calibrated_classifier = CalibratedClassifierCV(\n",
        "            self.binary_classifier,\n",
        "            method='isotonic',\n",
        "            cv=5\n",
        "        )\n",
        "        self.calibrated_classifier.fit(X_binary, y_binary)\n",
        "\n",
        "    def predict(self, X):\n",
        "        proba = self.calibrated_classifier.predict_proba(X)\n",
        "        max_proba = proba.max(axis=1)\n",
        "        binary_pred = proba.argmax(axis=1)\n",
        "\n",
        "        predictions = []\n",
        "        for i in range(len(X)):\n",
        "            if max_proba[i] >= self.threshold:\n",
        "                predictions.append('Biased' if binary_pred[i] == 1 else 'Non-biased')\n",
        "            else:\n",
        "                predictions.append('No agreement')\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "# Optimize threshold\n",
        "print(\"\\nOptimizing confidence threshold...\")\n",
        "best_threshold = None\n",
        "best_val_f1 = -1\n",
        "\n",
        "# Create balanced labels for optimization loop\n",
        "y_train_balanced_labels = label_encoder.inverse_transform(y_train_balanced)\n",
        "\n",
        "for threshold in np.arange(0.4, 0.8, 0.05):\n",
        "    clf = ConfidenceBasedClassifier(confidence_threshold=threshold)\n",
        "    # Pass y_train_balanced_labels to ensure mask length matches X_train_balanced\n",
        "    clf.fit(X_train_balanced, y_train_balanced, y_train_balanced_labels)\n",
        "\n",
        "    y_val_pred = clf.predict(X_val)\n",
        "    val_f1 = f1_score(y_val_labels, y_val_pred, average='macro',\n",
        "                     labels=['Biased', 'Non-biased', 'No agreement'])\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        best_threshold = threshold\n",
        "\n",
        "print(f\"âœ“ Optimal threshold: {best_threshold:.2f}\")\n",
        "print(f\"  Val F1 Macro: {best_val_f1:.4f}\")\n",
        "\n",
        "# Train final confidence-based model\n",
        "confidence_classifier = ConfidenceBasedClassifier(confidence_threshold=best_threshold)\n",
        "# Pass y_train_balanced_labels to ensure mask length matches X_train_balanced\n",
        "confidence_classifier.fit(X_train_balanced, y_train_balanced, y_train_balanced_labels)\n",
        "\n",
        "results_strategy2 = {\n",
        "    'Confidence-Based': {\n",
        "        'estimator': confidence_classifier,\n",
        "        'best_params': {'threshold': best_threshold},\n",
        "        'val_f1_macro': best_val_f1\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwa_8ln6lbnL",
        "outputId": "eecf398a-b867-4c24-908e-6e849cb41732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STRATEGY 2: CONFIDENCE-BASED CLASSIFICATION\n",
            "================================================================================\n",
            "\n",
            "Optimizing confidence threshold...\n",
            "âœ“ Optimal threshold: 0.55\n",
            "  Val F1 Macro: 0.5095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STRATEGY 3: DISAGREEMENT-BASED ENSEMBLE\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STRATEGY 3: DISAGREEMENT-BASED ENSEMBLE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "class DisagreementEnsemble:\n",
        "    def __init__(self, disagreement_threshold=0.5):\n",
        "        self.threshold = disagreement_threshold\n",
        "        self.base_models = {\n",
        "            'lr': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000, C=1.0, class_weight='balanced'),\n",
        "            'svm': SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE, C=1.0, class_weight='balanced'),\n",
        "            'rf': RandomForestClassifier(n_estimators=100, max_depth=15, random_state=RANDOM_STATE,\n",
        "                                        class_weight='balanced', n_jobs=-1)\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y_labels):\n",
        "        biased_mask = (y_labels == 'Biased')\n",
        "        non_biased_mask = (y_labels == 'Non-biased')\n",
        "        binary_mask = biased_mask | non_biased_mask\n",
        "\n",
        "        X_binary = X[binary_mask]\n",
        "        y_binary = biased_mask[binary_mask].astype(int)\n",
        "\n",
        "        for name, model in self.base_models.items():\n",
        "            model.fit(X_binary, y_binary)\n",
        "\n",
        "    def _calculate_disagreement(self, X):\n",
        "        predictions = np.array([model.predict(X) for model in self.base_models.values()])\n",
        "        disagreements = []\n",
        "        for i in range(X.shape[0]):\n",
        "            pred_dist = predictions[:, i]\n",
        "            unique, counts = np.unique(pred_dist, return_counts=True)\n",
        "            probs = counts / len(pred_dist)\n",
        "            disagreements.append(entropy(probs))\n",
        "        return np.array(disagreements)\n",
        "\n",
        "    def _get_ensemble_proba(self, X):\n",
        "        probas = [model.predict_proba(X) for model in self.base_models.values()]\n",
        "        return np.mean(probas, axis=0)\n",
        "\n",
        "    def predict(self, X):\n",
        "        disagreements = self._calculate_disagreement(X)\n",
        "        ensemble_proba = self._get_ensemble_proba(X)\n",
        "        binary_pred = ensemble_proba.argmax(axis=1)\n",
        "\n",
        "        predictions = []\n",
        "        for i in range(len(X)):\n",
        "            if disagreements[i] >= self.threshold:\n",
        "                predictions.append('No agreement')\n",
        "            else:\n",
        "                predictions.append('Biased' if binary_pred[i] == 1 else 'Non-biased')\n",
        "\n",
        "        return np.array(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTS2fwAzlgNW",
        "outputId": "c04672c1-1459-43e9-ca98-29188c7e1010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STRATEGY 3: DISAGREEMENT-BASED ENSEMBLE\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimize disagreement threshold\n",
        "print(\"\\nOptimizing disagreement threshold...\")\n",
        "temp_ensemble = DisagreementEnsemble()\n",
        "temp_ensemble.fit(X_train_balanced, y_train_labels)\n",
        "\n",
        "disagreements_val = temp_ensemble._calculate_disagreement(X_val)\n",
        "thresholds = np.percentile(disagreements_val, np.arange(20, 80, 10))\n",
        "\n",
        "best_disagreement_threshold = None\n",
        "best_val_f1 = -1\n",
        "\n",
        "for threshold in thresholds:\n",
        "    ensemble = DisagreementEnsemble(disagreement_threshold=threshold)\n",
        "    ensemble.fit(X_train_balanced, y_train_labels)\n",
        "\n",
        "    y_val_pred = ensemble.predict(X_val)\n",
        "    val_f1 = f1_score(y_val_labels, y_val_pred, average='macro',\n",
        "                     labels=['Biased', 'Non-biased', 'No agreement'])\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        best_disagreement_threshold = threshold\n",
        "\n",
        "print(f\"âœ“ Optimal disagreement threshold: {best_disagreement_threshold:.3f}\")\n",
        "print(f\"  Val F1 Macro: {best_val_f1:.4f}\")\n",
        "\n",
        "# Train final ensemble\n",
        "disagreement_ensemble = DisagreementEnsemble(disagreement_threshold=best_disagreement_threshold)\n",
        "disagreement_ensemble.fit(X_train_balanced, y_train_labels)\n",
        "\n",
        "results_strategy3 = {\n",
        "    'Disagreement Ensemble': {\n",
        "        'estimator': disagreement_ensemble,\n",
        "        'best_params': {'threshold': best_disagreement_threshold},\n",
        "        'val_f1_macro': best_val_f1\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "qXcoGCKAlnxL",
        "outputId": "f83b0a4c-79b0-4bec-c91b-b4e74954569f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimizing disagreement threshold...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "boolean index did not match indexed array along axis 0; size of axis is 953 but size of corresponding boolean axis is 1020",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-33308680.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nOptimizing disagreement threshold...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtemp_ensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDisagreementEnsemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtemp_ensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_balanced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdisagreements_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_ensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_disagreement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-634950391.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y_labels)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mbinary_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbiased_mask\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mnon_biased_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mX_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbinary_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0my_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbiased_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbinary_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along axis 0; size of axis is 953 but size of corresponding boolean axis is 1020"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 4: COMPARE ALL STRATEGIES ON VALIDATION SET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STEP 4: COMPARING ALL STRATEGIES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Combine all results\n",
        "all_results = {}\n",
        "all_results.update(results_strategy1)\n",
        "all_results.update(results_strategy2)\n",
        "all_results.update(results_strategy3)\n",
        "\n",
        "# Sort by validation F1\n",
        "sorted_results = sorted(all_results.items(),\n",
        "                       key=lambda x: x[1]['val_f1_macro'],\n",
        "                       reverse=True)\n",
        "\n",
        "print(f\"\\n{'Model':<30} {'Val F1 Macro':<15}\")\n",
        "print(\"-\" * 50)\n",
        "for rank, (model_name, result) in enumerate(sorted_results, 1):\n",
        "    marker = \"ðŸ†\" if rank == 1 else f\"{rank}.\"\n",
        "    print(f\"{marker} {model_name:<28} {result['val_f1_macro']:.4f}\")\n",
        "\n",
        "# Select best model\n",
        "best_model_name = sorted_results[0][0]\n",
        "best_model = sorted_results[0][1]['estimator']\n",
        "\n",
        "print(f\"\\nâœ… BEST MODEL: {best_model_name}\")\n",
        "print(f\"   Validation F1 Macro: {sorted_results[0][1]['val_f1_macro']:.4f}\")\n"
      ],
      "metadata": {
        "id": "FibrPR-nlwQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# STEP 5: FINAL EVALUATION ON TEST SET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STEP 5: FINAL EVALUATION ON TEST SET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Predict on test set\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "\n",
        "# Convert to labels if needed\n",
        "if isinstance(y_test_pred[0], (int, np.integer)):\n",
        "    y_test_pred_labels = label_encoder.inverse_transform(y_test_pred)\n",
        "else:\n",
        "    y_test_pred_labels = y_test_pred\n",
        "\n",
        "# Classification report\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(\"-\" * 80)\n",
        "print(classification_report(y_test_labels, y_test_pred_labels, digits=4))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(\"-\" * 80)\n",
        "cm = confusion_matrix(y_test_labels, y_test_pred_labels,\n",
        "                     labels=['Biased', 'Non-biased', 'No agreement'])\n",
        "cm_df = pd.DataFrame(cm,\n",
        "                     index=['Biased', 'Non-biased', 'No agreement'],\n",
        "                     columns=['Biased', 'Non-biased', 'No agreement'])\n",
        "print(cm_df)\n",
        "\n",
        "# Calculate final metrics\n",
        "test_f1_macro = f1_score(y_test_labels, y_test_pred_labels, average='macro',\n",
        "                         labels=['Biased', 'Non-biased', 'No agreement'])\n",
        "test_f1_weighted = f1_score(y_test_labels, y_test_pred_labels, average='weighted')\n",
        "test_accuracy = accuracy_score(y_test_labels, y_test_pred_labels)\n",
        "\n",
        "print(f\"\\nðŸ“Š FINAL TEST METRICS:\")\n",
        "print(f\"  Macro F1:    {test_f1_macro:.4f}\")\n",
        "print(f\"  Weighted F1: {test_f1_weighted:.4f}\")\n",
        "print(f\"  Accuracy:    {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "XfXF8A_LlzDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 6: SAVE BEST MODEL\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STEP 6: SAVING BEST MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "joblib.dump(best_model, '/content/best_model_final.pkl')\n",
        "print(f\"âœ“ Saved: best_model_final.pkl\")\n",
        "\n",
        "# Save metadata\n",
        "metadata = {\n",
        "    'model_name': best_model_name,\n",
        "    'test_f1_macro': test_f1_macro,\n",
        "    'test_f1_weighted': test_f1_weighted,\n",
        "    'test_accuracy': test_accuracy,\n",
        "    'best_params': sorted_results[0][1]['best_params'],\n",
        "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "}\n",
        "joblib.dump(metadata, '/content/model_metadata.pkl')\n",
        "print(f\"âœ“ Saved: model_metadata.pkl\")"
      ],
      "metadata": {
        "id": "BGpdTM3Yl1xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOlnbP92juHs"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"NOTEBOOK 2 COMPLETE - FINAL SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nðŸ† BEST MODEL: {best_model_name}\")\n",
        "print(f\"\\nðŸ“Š TEST SET PERFORMANCE:\")\n",
        "print(f\"  Macro F1:    {test_f1_macro:.4f} {'âœ… TARGET MET!' if test_f1_macro >= 0.80 else 'âŒ Below 0.80 target'}\")\n",
        "print(f\"  Weighted F1: {test_f1_weighted:.4f}\")\n",
        "print(f\"  Accuracy:    {test_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nðŸ’¾ SAVED FILES:\")\n",
        "print(f\"  1. best_model_final.pkl - Best trained model\")\n",
        "print(f\"  2. model_metadata.pkl - Model metadata\")\n",
        "\n",
        "if test_f1_macro < 0.80:\n",
        "    print(f\"\\nðŸ’¡ RECOMMENDATIONS TO IMPROVE:\")\n",
        "    print(f\"  1. Review 'samples_for_review.xlsx' and clean data\")\n",
        "    print(f\"  2. Consider treating 'No agreement' as binary uncertainty\")\n",
        "    print(f\"  3. Collect more training data, especially for 'No agreement'\")\n",
        "    print(f\"  4. Try domain-specific fine-tuning of embeddings\")\n",
        "else:\n",
        "    print(f\"\\nðŸŽ‰ TARGET ACHIEVED! Model ready for deployment.\")\n",
        "\n",
        "print(\"\\nâž¡ï¸  NEXT STEP:\")\n",
        "print(\"  Run Notebook 3 for inference and LIME explainability\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7860c8d4"
      },
      "source": [
        "# Task\n",
        "The current error is in the `DisagreementEnsemble.fit` method, where `X_train_balanced` is passed along with `y_train_labels`. The fix is to use `y_train_balanced_labels` instead of `y_train_labels` when calling `fit` for the `DisagreementEnsemble` class, similar to how it was resolved for the `ConfidenceBasedClassifier`. This ensures that the feature matrix `X` and the corresponding labels `y_labels` have matching dimensions for the binary classification task within the ensemble models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac1805e5"
      },
      "source": [
        "## qXcoGCKAlnxL\n",
        "\n",
        "### Subtask:\n",
        "Fix the IndexError in the DisagreementEnsemble.fit method by using `y_train_balanced_labels` instead of `y_train_labels`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1467a272"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The primary issue encountered was an `IndexError` within the `DisagreementEnsemble.fit` method.\n",
        "*   This error stemmed from a mismatch between the input feature matrix `X_train_balanced` and the label vector `y_train_labels`, specifically during the training of the binary classification task models within the ensemble.\n",
        "*   The `y_train_labels` were not aligned dimensionally with the balanced feature set `X_train_balanced`, leading to the `IndexError`.\n",
        "*   The resolution involved replacing `y_train_labels` with `y_train_balanced_labels` when calling the `fit` method, ensuring that both the features and labels corresponded to the balanced dataset.\n",
        "*   This fix was consistent with a prior resolution for the `ConfidenceBasedClassifier`, highlighting a recurring pattern in handling balanced datasets.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Always ensure that feature matrices and their corresponding label vectors have compatible dimensions and represent the same data subsets, especially after data balancing or sampling operations.\n",
        "*   Consider implementing pre-training validation checks for data shape and consistency to proactively catch such alignment issues before they lead to runtime errors.\n"
      ]
    }
  ]
}